{"meta":{"title":"A Visual Guided Reinforcement Learning Agent","subtitle":"CS527","description":"","author":"Yingqi Lin, Tianyi Xue","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"Team Member","slug":"Team","date":"2021-11-30T12:37:05.000Z","updated":"2021-11-30T21:48:56.361Z","comments":true,"path":"2021/11/30/Team/","link":"","permalink":"http://example.com/2021/11/30/Team/","excerpt":"","text":"Tianyi Xue: http://linkedin.com/in/tianyi-xue-3a039aa4Yingqi Lin: http://linkedin.com/in/yingqi-lin-aa61371b4","categories":[],"tags":[]},{"title":"Demo","slug":"Demo","date":"2021-11-30T03:37:28.000Z","updated":"2021-11-30T21:21:20.945Z","comments":true,"path":"2021/11/30/Demo/","link":"","permalink":"http://example.com/2021/11/30/Demo/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"EDD and Techinical Paper","slug":"Simulation_Scene","date":"2021-11-29T18:37:28.000Z","updated":"2021-11-30T21:36:44.253Z","comments":true,"path":"2021/11/30/Simulation_Scene/","link":"","permalink":"http://example.com/2021/11/30/Simulation_Scene/","excerpt":"","text":"EDD and Techinical PaperEDD: https://drive.google.com/file/d/1m64es_KjL0pXW32-8ocU8QczwcaJjY-1/view?usp=sharingTechnical Paper: https://drive.google.com/file/d/14jszbTqwJ5FWLdTkizfdwl7crFhKsWsn/view?usp=sharing","categories":[],"tags":[]},{"title":"Project Goal","slug":"Project Goal","date":"2021-11-29T17:37:28.000Z","updated":"2021-11-30T18:39:30.888Z","comments":true,"path":"2021/11/30/Project Goal/","link":"","permalink":"http://example.com/2021/11/30/Project%20Goal/","excerpt":"","text":"Project GoalA robot agent that navigates to a point goal in a mapless environment while avoiding obstacles and detecting surrounding objects","categories":[],"tags":[]},{"title":"Introduction","slug":"Introduction","date":"2021-11-29T16:37:28.000Z","updated":"2021-11-30T18:38:39.299Z","comments":true,"path":"2021/11/30/Introduction/","link":"","permalink":"http://example.com/2021/11/30/Introduction/","excerpt":"","text":"IntroductionPath planning has been studied extensively over the last few decades. In the real world not every navigation task is map-based even though map-based navigation algorithms such as A* and uniform-cost search can compute optimal path veryfast. Other algorithms such as SLAM can compute the mapbut not every robot is equipped with LiDAR sensors and thecomputation costs are high. In this paper, we focus on theproblem of item searching in a map-less environment usingonly visual input. Our agent is trained with object detectionalgorithms such as CNN to be able to detect a certain setof objects. The agent will then exploit various reinforcementlearning algorithms to generate efficient policies to get to thedestination object from random spawn points with minimumcollisions. In our approach, we use object detection algorithmsto acquire the surrounding environment and collect the reward,which will then be fed into the reinforcement learning modelsto generate navigation policies. We evaluate our method in theiGibson environment to examine its effectiveness.","categories":[],"tags":[]}],"categories":[],"tags":[]}